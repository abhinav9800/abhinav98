{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav9800/abhinav98/blob/main/image_classification_using_EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset - https://www.kaggle.com/datasets/pavansanagapati/images-dataset\n",
        "# The dataset contains images of cars, cats, flowers, horses, humans, dogs, and bikes."
      ],
      "metadata": {
        "id": "Jz8MG9YWY_tl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_TyLy7FRTyAX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d pavansanagapati/images-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0BFs4ZfTypM",
        "outputId": "b1b95854-b5a0-4469-b980-caeb03373ae8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading images-dataset.zip to /content\n",
            " 99% 1.01G/1.01G [00:07<00:00, 44.1MB/s]\n",
            "100% 1.01G/1.01G [00:07<00:00, 138MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/images-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "SHHsz09PT85p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/train\n",
        "!mkdir /content/data/test"
      ],
      "metadata": {
        "id": "M_A8RP_PTzVD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "M-LCipSLTzXv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8HLRD6zTzcn",
        "outputId": "51789845-4ea5-45d0-bfc3-9754c13ebc00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import efficientnet.keras as efn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "yIqPRCSITzfS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = efn.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    classes=7,\n",
        "    input_shape=(150, 150, 3),\n",
        "    drop_connect_rate=0.4\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEV_iBBjTzhg",
        "outputId": "db41f472-0dec-4edf-c6bf-3d2e4a40e41b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16804768/16804768 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data_paths, train_base_folder, test_base_folder, train_ratio=0.85):\n",
        "    \"\"\"\n",
        "    Splits the image datasets into train and test datasets.\n",
        "\n",
        "    Args:\n",
        "    - data_paths (dict): A dictionary mapping category names to their respective data paths.\n",
        "    - train_base_folder (str): The base folder where the train dataset will be stored.\n",
        "    - test_base_folder (str): The base folder where the test dataset will be stored.\n",
        "    - train_ratio (float): The ratio of images to be allocated for the training dataset.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "    random.seed(42)\n",
        "\n",
        "    for category, data_path in data_paths.items():\n",
        "\n",
        "        train_folder = os.path.join(train_base_folder, category)\n",
        "        test_folder = os.path.join(test_base_folder, category)\n",
        "\n",
        "        for folder_path in [train_folder, test_folder]:\n",
        "            if not os.path.exists(folder_path):\n",
        "                os.makedirs(folder_path)\n",
        "\n",
        "        imgs_list = [filename for filename in os.listdir(data_path) if os.path.splitext(filename)[-1] in image_extensions]\n",
        "\n",
        "        random.shuffle(imgs_list)\n",
        "\n",
        "        train_size = int(len(imgs_list) * train_ratio)\n",
        "        test_size = len(imgs_list) - train_size\n",
        "\n",
        "        for i, f in enumerate(imgs_list):\n",
        "            if i < train_size:\n",
        "                dest_folder = train_folder\n",
        "            else:\n",
        "                dest_folder = test_folder\n",
        "            shutil.copy(os.path.join(data_path, f), os.path.join(dest_folder, f))\n",
        "\n",
        "# Example usage:\n",
        "data_paths = {\n",
        "    \"car\": \"/content/data/cars\",\n",
        "    \"cat\": \"/content/data/cats\",\n",
        "    \"flower\": \"/content/data/flowers\",\n",
        "    \"horse\": \"/content/data/horses\",\n",
        "    \"human\": \"/content/data/human\",\n",
        "    \"dog\": \"/content/data/dogs\",\n",
        "    \"bike\": \"/content/data/bike\"\n",
        "}\n",
        "\n",
        "train_base_folder = \"/content/data/train\"\n",
        "test_base_folder = \"/content/data/test\"\n",
        "\n",
        "split_data(data_paths, train_base_folder, test_base_folder)\n"
      ],
      "metadata": {
        "id": "YoAuvqa7TzkM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os"
      ],
      "metadata": {
        "id": "lYLuW4UZTznT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_images(train_dirs, batch_size=32, target_size=(150, 150), augmentation_parameters=None):\n",
        "    if augmentation_parameters is None:\n",
        "        augmentation_parameters = {\n",
        "            'rescale': 1./255,\n",
        "            'shear_range': 0.2,\n",
        "            'zoom_range': 0.2,\n",
        "            'horizontal_flip': True\n",
        "        }\n",
        "\n",
        "    \"\"\"\n",
        "    Function to augment images in specified directories using Keras ImageDataGenerator.\n",
        "\n",
        "    Args:\n",
        "    - train_dirs (list): List of directories containing the training images.\n",
        "    - batch_size (int): Batch size for data augmentation.\n",
        "    - target_size (tuple): Tuple specifying the target size of the images (height, width).\n",
        "    - augmentation_parameters (dict): Dictionary of augmentation parameters for ImageDataGenerator.\n",
        "                                      Defaults to None, which uses predefined augmentation parameters.\n",
        "\n",
        "    Returns:\n",
        "    - train_generator (DirectoryIterator): Iterator for training data.\n",
        "    - validation_generator (DirectoryIterator): Iterator for validation data.\n",
        "    \"\"\"\n",
        "\n",
        "    train_datagen = ImageDataGenerator(**augmentation_parameters)\n",
        "\n",
        "    for data_dir in train_dirs:\n",
        "        image_files = os.listdir(data_dir)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(data_dir, image_file)\n",
        "            image = load_img(image_path)\n",
        "            image_array = img_to_array(image)\n",
        "            image_array = image_array.reshape((1,) + image_array.shape)\n",
        "\n",
        "            i = 0\n",
        "            for batch in train_datagen.flow(image_array,\n",
        "                                             batch_size=1,\n",
        "                                             save_to_dir=data_dir,\n",
        "                                             save_prefix='augmented_' + image_file.split('.')[0],\n",
        "                                             save_format='jpg'):\n",
        "                i += 1\n",
        "                if i >= 2:\n",
        "                    break\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/train',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/data/test',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "# Example usage\n",
        "train_dirs = [\"/content/data/train/bike\",\n",
        "              \"/content/data/train/car\",\n",
        "              \"/content/data/train/cat\",\n",
        "              \"/content/data/train/flower\",\n",
        "              \"/content/data/train/horse\",\n",
        "              \"/content/data/train/human\",\n",
        "              \"/content/data/train/dog\"]\n",
        "\n",
        "train_generator, validation_generator = augment_images(train_dirs, batch_size=32, target_size=(150, 150))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS8Lx_4VwCBW",
        "outputId": "02efdfb2-6b66-41c9-e7a5-60b2b413516f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4576 images belonging to 7 classes.\n",
            "Found 274 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "metadata": {
        "id": "7EovdppaTztY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/data/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/data/test',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ry7qttsUhBA",
        "outputId": "d1930ac9-98f8-444f-9c9b-3f8a08d3610a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4576 files belonging to 7 classes.\n",
            "Found 274 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image, label):\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ],
      "metadata": {
        "id": "Gn0DpYJJUhDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "W60cUl5lUhIj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=2)\n",
        "\n",
        "history = model.fit(train_ds, epochs=10, validation_data=validation_ds,callbacks=[early_stopping_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCvjLyMeUhLO",
        "outputId": "9b6ded26-618d-44c9-f96a-30b1c1b58c4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "143/143 [==============================] - 51s 160ms/step - loss: 0.7538 - accuracy: 0.7533 - val_loss: 0.2662 - val_accuracy: 0.9161\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 20s 134ms/step - loss: 0.1479 - accuracy: 0.9613 - val_loss: 0.1501 - val_accuracy: 0.9599\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 20s 135ms/step - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.1177 - val_accuracy: 0.9708\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 19s 133ms/step - loss: 0.0304 - accuracy: 0.9921 - val_loss: 0.0990 - val_accuracy: 0.9745\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 19s 133ms/step - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.1065 - val_accuracy: 0.9745\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 20s 138ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.1020 - val_accuracy: 0.9745\n"
          ]
        }
      ]
    }
  ]
}